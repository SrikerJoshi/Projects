{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#install open ai if not installed already \"pip install openai\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import openai\nimport time\n\nopenai.api_key = \"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\"\n\ndef chat_with_gpt(chat_log, max_retries=3):\n    retries = 0\n    while retries < max_retries:\n        try:\n            response = openai.ChatCompletion.create(\n                model='gpt-3.5-turbo',\n                messages=chat_log\n            )\n            return response.choices[0].message['content'].strip()\n        \n        # Catch general OpenAI errors\n        except Exception as e:\n            # Handle specific error messages for rate limiting\n            if 'Rate limit' in str(e):\n                retries += 1\n                print(f\"Rate limit exceeded. Retrying {retries}/{max_retries}...\")\n                time.sleep(5)\n            else:\n                print(f\"An error occurred: {str(e)}\")\n                break\n    return \"Failed to get a response due to repeated errors.\"\n\nif __name__ == \"__main__\":\n    chat_log = []\n    n_remembered_post = 2\n    \n    while True:\n        user_input = input(\"You: \")\n        if user_input.lower() in ['quit', \"exit\", \"bye\"]:\n            break\n\n        chat_log.append({'role': 'user', 'content': user_input})\n\n        if len(chat_log) > n_remembered_post:\n            del chat_log[:len(chat_log)-n_remembered_post]\n\n        response = chat_with_gpt(chat_log)\n        print(\"Chatbot:\", response)\n        chat_log.append({'role': \"assistant\", 'content': response})\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-05T20:42:58.152139Z","iopub.execute_input":"2024-09-05T20:42:58.152512Z","iopub.status.idle":"2024-09-05T20:43:18.556823Z","shell.execute_reply.started":"2024-09-05T20:42:58.152475Z","shell.execute_reply":"2024-09-05T20:43:18.555591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}