{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59a43e2",
   "metadata": {},
   "source": [
    "# Importing the inbuilt libraries for pytorch and iteration tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5992ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5311b",
   "metadata": {},
   "source": [
    "# Check if CUDA if it is available and get the number of available GPUs as I am are using multiple GPUs for this CNN. (parallel computing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a85f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "num_gpus = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d10609",
   "metadata": {},
   "source": [
    "# Defining transforms with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6699795",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245bcdd",
   "metadata": {},
   "source": [
    "# Adjusting the batch size and number of workers based on the number of GPUs available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd46b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjoshi2/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size_per_gpu = 32\n",
    "num_workers_per_gpu = 4\n",
    "batch_size = batch_size_per_gpu * num_gpus\n",
    "num_workers = num_workers_per_gpu * num_gpus\n",
    "\n",
    "# Load CIFAR-10 dataset with updated batch size and number of workers\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d7209",
   "metadata": {},
   "source": [
    "# Defining a function for creating and fine-tuning ResNet-18 model for CIFAR-10 classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb9220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_resnet18(nodes_hidden, strength_regularization, use_batch_norm):\n",
    "    # Load pre-trained ResNet-18 model\n",
    "    resnet = models.resnet18(weights=torchvision.models.resnet.ResNet18_Weights.DEFAULT)\n",
    "    \n",
    "    # Modify the fully connected layer to have the specified number of nodes in hidden layer\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(num_ftrs, nodes_hidden)\n",
    "    \n",
    "    # If using batch normalization, replace the BatchNorm layers with GroupNorm layers\n",
    "    if use_batch_norm:\n",
    "        resnet = replace_bn_with_gn(resnet)\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    resnet = resnet.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer with weight decay\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9, weight_decay=strength_regularization)\n",
    "    \n",
    "    # Train the model for 10 epochs\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        resnet.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    # Test the model after 10 epochs\n",
    "    resnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total * 100\n",
    "    print(f'Accuracy of the network on the {total} test images after 10 epochs: {accuracy}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4884f63",
   "metadata": {},
   "source": [
    "### Replace batch normalization with group normalization and perform a grid search to find the best hyper parameter in the list of hyper parameters namely\n",
    "### nodes_hidden_list = [64, 128, 256]  this is the number of nodes in the hidden layer\n",
    "### strength_regularization_list = [0.0001, 0.001, 0.01]\n",
    "### use_batch_norm_values = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41d1edb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with nodes_hidden=64, strength_regularization=0.0001, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.91000000000001%\n",
      "Training model with nodes_hidden=64, strength_regularization=0.0001, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 80.99%\n",
      "Training model with nodes_hidden=64, strength_regularization=0.001, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 80.78999999999999%\n",
      "Training model with nodes_hidden=64, strength_regularization=0.001, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.78999999999999%\n",
      "Training model with nodes_hidden=64, strength_regularization=0.01, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 82.5%\n",
      "Training model with nodes_hidden=64, strength_regularization=0.01, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 82.08%\n",
      "Training model with nodes_hidden=128, strength_regularization=0.0001, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.58%\n",
      "Training model with nodes_hidden=128, strength_regularization=0.0001, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.31%\n",
      "Training model with nodes_hidden=128, strength_regularization=0.001, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.78999999999999%\n",
      "Training model with nodes_hidden=128, strength_regularization=0.001, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.67%\n",
      "Training model with nodes_hidden=128, strength_regularization=0.01, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 82.37%\n",
      "Training model with nodes_hidden=128, strength_regularization=0.01, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.76%\n",
      "Training model with nodes_hidden=256, strength_regularization=0.0001, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.03%\n",
      "Training model with nodes_hidden=256, strength_regularization=0.0001, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.31%\n",
      "Training model with nodes_hidden=256, strength_regularization=0.001, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.72%\n",
      "Training model with nodes_hidden=256, strength_regularization=0.001, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 81.24%\n",
      "Training model with nodes_hidden=256, strength_regularization=0.01, use_batch_norm=True\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 82.58%\n",
      "Training model with nodes_hidden=256, strength_regularization=0.01, use_batch_norm=False\n",
      "Accuracy of the network on the 10000 test images after 10 epochs: 82.45%\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'nodes_hidden': 256, 'strength_regularization': 0.01, 'use_batch_norm': True}\n",
      "Best accuracy: 82.58\n"
     ]
    }
   ],
   "source": [
    "def replace_bn_with_gn(model):\n",
    "    # Create a copy of the model's state dictionary\n",
    "    state_dict_copy = model.state_dict()\n",
    "\n",
    "    # Iterate over the copied dictionary\n",
    "    for name, module in state_dict_copy.items():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            num_groups = 32  # Assuming 32 as the default number of groups\n",
    "            gn = nn.GroupNorm(num_groups, module.num_features, eps=module.eps, affine=module.affine)\n",
    "            state_dict_copy[name] = gn\n",
    "    # Load the modified state dictionary back into the model\n",
    "    model.load_state_dict(state_dict_copy)\n",
    "    return model\n",
    "\n",
    "# Perform grid search for different hyperparameters\n",
    "nodes_hidden_list = [64, 128, 256]\n",
    "strength_regularization_list = [0.0001, 0.001, 0.01]\n",
    "use_batch_norm_values = [True, False]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {} \n",
    "\n",
    "for nodes_hidden, strength_regularization, use_bn in itertools.product(nodes_hidden_list, strength_regularization_list, use_batch_norm_values):\n",
    "    print(f\"Training model with nodes_hidden={nodes_hidden}, strength_regularization={strength_regularization}, use_batch_norm={use_bn}\")\n",
    "    accuracy = fine_tune_resnet18(nodes_hidden, strength_regularization, use_bn)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = {'nodes_hidden': nodes_hidden, 'strength_regularization': strength_regularization, 'use_batch_norm': use_bn}\n",
    "\n",
    "print(\"Grid search complete.\")\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d156d4",
   "metadata": {},
   "source": [
    "# Best accuracy obtained after 10 epochs is 82.58% for 10000 images in the test set and the best hyper parameters are 'nodes_hidden'= 256, 'strength_regularization'= 0.01, 'use_batch_norm'= True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf643279",
   "metadata": {},
   "source": [
    "### To further improve the performance and get a better accuracy percentage I increased the number of epochs from 10 to 50 and tuned other hyper parameters like learning rate and weight decay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03fdca",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba20a9",
   "metadata": {},
   "source": [
    "### learning_rates = [0.001, 0.01, 0.1]\n",
    "### weight_decays = [0.0001, 0.00001, 0.000001]\n",
    "### initially I have taken a set of hyper parameters as hypothesis parameters that i thought would give the best accuracy, they were learning rate = 0.01 , weight_decay = 0.0001 but later I have commented that code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787602b",
   "metadata": {},
   "source": [
    "# Define a function for creating and training the model with given hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db328a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with learning rate=0.001 and weight decay=0.0001\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 85.15%\n",
      "Training model with learning rate=0.001 and weight decay=1e-05\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 85.25%\n",
      "Training model with learning rate=0.001 and weight decay=1e-06\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 85.16%\n",
      "Training model with learning rate=0.01 and weight decay=0.0001\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 85.33%\n",
      "Training model with learning rate=0.01 and weight decay=1e-05\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 85.18%\n",
      "Training model with learning rate=0.01 and weight decay=1e-06\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 85.65%\n",
      "Training model with learning rate=0.1 and weight decay=0.0001\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 79.1%\n",
      "Training model with learning rate=0.1 and weight decay=1e-05\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 74.07%\n",
      "Training model with learning rate=0.1 and weight decay=1e-06\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 69.49%\n",
      "Grid search complete.\n",
      "Best hyperparameters: {'learning_rate': 0.01, 'weight_decay': 1e-06}\n",
      "Best accuracy: 85.65\n",
      "Accuracy of the network on the 10000 test images after 50 epochs: 86.44%\n",
      "Best Learning Rate: 0.01, Best Weight Decay: 1e-06, Best Accuracy: 85.65%\n"
     ]
    }
   ],
   "source": [
    "def train_model(learning_rate, weight_decay):\n",
    "    # Load pre-trained ResNet-18 model with the most up-to-date weights\n",
    "    resnet = models.resnet18(weights=torchvision.models.resnet.ResNet18_Weights.DEFAULT).to(device)\n",
    "\n",
    "    # Modify the last fully connected layer to have 10 output classes for CIFAR-10\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(num_ftrs, 10).to(device)\n",
    "\n",
    "    # Wrap the model with nn.DataParallel to use multiple GPUs\n",
    "    resnet = nn.DataParallel(resnet)\n",
    "\n",
    "    # Define loss function and optimizer with weight decay\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(resnet.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "    # Train the model for a reduced number of epochs\n",
    "    num_epochs = 50\n",
    "    resnet.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # Test the model\n",
    "    resnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = resnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the {total} test images after 50 epochs: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "# Perform grid search for different learning rates and weight decays\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "weight_decays = [0.0001, 0.00001, 0.000001]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for wd in weight_decays:\n",
    "        print(f\"Training model with learning rate={lr} and weight decay={wd}\")\n",
    "        accuracy = train_model(lr, wd)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters = {'learning_rate': lr, 'weight_decay': wd}\n",
    "\n",
    "print(\"Grid search complete.\")\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "\n",
    "# printing the accuracy for a random guess of learning rate = 0.01 and weight_decay= 0.0001\n",
    "#learning rate = 0.01\n",
    "#weight_decay = 0.0001\n",
    "#accuracy = train_model(learning_rate, weight_decay)\n",
    "#print(f'Learning Rate: {learning_rate}, Weight Decay: {weight_decay}, Accuracy: {accuracy}%')\n",
    "\n",
    "# but found that learning rate = 0.01 and weight_decay = 0.000001 are the best hyper parametrs\n",
    "accuracy = train_model(best_hyperparameters['learning_rate'], best_hyperparameters['weight_decay'])\n",
    "print(f'Best Learning Rate: {best_hyperparameters[\"learning_rate\"]}, Best Weight Decay: {best_hyperparameters[\"weight_decay\"]}, Best Accuracy: {best_accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d02624",
   "metadata": {},
   "source": [
    "unexpectedly I have printed the wrong accuracy in the last line instead of accuracy from the last iteration I printed the second last, but the final accuracy obtained is 86.44% for the 10000 images in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f23531",
   "metadata": {},
   "source": [
    "# Finally after training the model over 50 epochs we were able to reach a test accuracy of 86.44 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8ab67",
   "metadata": {},
   "source": [
    "# The best hyper parameters that got me this accuracy were.\n",
    "# Best Learning Rate: 0.01, Best Weight Decay: 1e-06"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
