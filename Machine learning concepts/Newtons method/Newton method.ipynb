{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min increment change of parameters hass been reached!\n",
      "0.9640287769784173\n",
      "0.9640287769784173\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9568345323741008\n",
      "0.9568345323741008\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9496402877697842\n",
      "0.9496402877697842\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9928057553956835\n",
      "0.9928057553956835\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9712230215827338\n",
      "0.9712230215827338\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9568345323741008\n",
      "0.9568345323741008\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9856115107913669\n",
      "0.9856115107913669\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9712230215827338\n",
      "0.9712230215827338\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9712230215827338\n",
      "0.9712230215827338\n",
      "The min increment change of parameters hass been reached!\n",
      "0.9784172661870504\n",
      "0.9784172661870504\n",
      "Mine implement: the average accuracy over 10 trials is  0.9697841726618703\n",
      "Scikit Learn: the average accuracy over 10 trials is  0.9697841726618703\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import linalg\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Data\n",
    "class dataset:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.data = self.loadData()\n",
    "        \n",
    "    # load data\n",
    "    # Input: file path, data type, delimiter\n",
    "    # Output: a numpy array\n",
    "    def loadData(self, dt = str, deli =','):\n",
    "        data = np.loadtxt(self.filename, dtype = dt, delimiter = deli)\n",
    "        # Replace the missing data '?' with '0'\n",
    "        for line in data:\n",
    "            line[line == '?'] = '0'\n",
    "        return data.astype(int)\n",
    "    \n",
    "    # Split the data into train and test randomly with specified ratio \n",
    "    # Input: data, ratio\n",
    "    # Output: four numpy array: X_train, X_test, y_train, y_test\n",
    "    def split(self, ratio = 0.2):\n",
    "        n = self.data.shape[0]\n",
    "        np.random.shuffle(self.data)\n",
    "        # the size of data Multiple split ratio\n",
    "        offset = int(n * ratio)\n",
    "        # X is a list of features (remove sample ID), y is a list of labels\n",
    "        X_train, X_test, y_train, y_test = self.data[offset:,1:-1], self.data[:offset,1:-1], \\\n",
    "        self.data[offset:, -1], self.data[:offset,-1]\n",
    "        # Using 0, 1 Instead of 2, 4 of labels\n",
    "        y_train = [0 if (x == 2) else 1 for x in y_train]\n",
    "        y_test = [0 if (x == 2) else 1 for x in y_test]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    \n",
    "# Model   \n",
    "class mineLogisticRegression:\n",
    "    def __init__(self, X, y):\n",
    "        # n is the number of features\n",
    "        _, n = X.shape\n",
    "        # Initial weight values [w0, w1, ... , wn] with 0\n",
    "        self.estimatedParas = np.zeros(n+1)\n",
    "        self.alpha = 0.001/(len(y))\n",
    "    \n",
    "    # Calculate estimation values p(x) using possibility function (logistical regression model)\n",
    "    def calProbability(self, X):\n",
    "        e = np.exp(np.dot(self.estimatedParas, X.T))\n",
    "        return e/(1 + e)\n",
    "    \n",
    "    # Calculate first derivation of log likelihood\n",
    "    def firstDerivative(self, X, y, py):\n",
    "        # L2 regularization\n",
    "        regular1 = self.alpha * self.estimatedParas\n",
    "        # sum(y_i - p(x) * x_ij)\n",
    "        return np.dot((y - py),X) + regular1\n",
    "     \n",
    "    # Calculate second derivation of log likelihood\n",
    "    def secondDerivative(self, X, py):\n",
    "        # L2 regularization\n",
    "        regular2 = self.alpha * np.eye(len(self.estimatedParas))\n",
    "        # sum(x_ij * x_jk * p(x_i) * (1 - p(x_i)))\n",
    "        prob = py*(1-py)\n",
    "        xProb = np.array([i*j for (i,j) in zip(X, prob)])\n",
    "        return -1*np.dot(xProb.T, X) + regular2\n",
    " \n",
    "    # Update estimated parameters by using Newton Method\n",
    "    def newtonMethodParaUpdate(self, derivative1, derivative2):\n",
    "        # next parameter = last parameter value - derivative2/derivative1\n",
    "        ratio = np.dot(linalg.inv(derivative2),derivative1)\n",
    "        self.estimatedParas = self.estimatedParas - ratio\n",
    " \n",
    "    # Fit model \n",
    "    # Input: trianing data, max iterations and min increment changes of parameter\n",
    "    # It will stop training when parameters won't change or \n",
    "    # it reaches max iterations or min increment (stable) \n",
    "    def fit(self, X, y, maxIteration, minIncrement):\n",
    "        \n",
    "        # Store last estimated parameter values\n",
    "        lastEstimatedParas = []\n",
    "        \n",
    "        # calculating intercepts\n",
    "        intercepts = np.ones((X.shape[0], 1))\n",
    "        X = np.c_[X, intercepts]\n",
    "        \n",
    "        # Initial iteration value\n",
    "        iteration = 0\n",
    " \n",
    "        # training model\n",
    "        while(list(self.estimatedParas) != list(lastEstimatedParas)):\n",
    "            # Record last estimated parameter values\n",
    "            lastEstimatedParas = self.estimatedParas\n",
    "            # Estimated y\n",
    "            py = self.calProbability(X)\n",
    "            # First derivative\n",
    "            derivative1 = self.firstDerivative(X, y, py)\n",
    "            # Second derivative\n",
    "            derivative2 = self.secondDerivative(X, py)\n",
    "            # Update estimated parameter value\n",
    "            self.newtonMethodParaUpdate(derivative1, derivative2)\n",
    "            # Update iteration value\n",
    "            iteration += 1\n",
    "            # Calculate increment value between last estimated parameter and current one\n",
    "            increment = linalg.norm(self.estimatedParas - lastEstimatedParas)\n",
    "            # Stop when it reaches max iterations\n",
    "            if(iteration > maxIteration):\n",
    "                print(\"The max iteration has been reached!\")\n",
    "                break\n",
    "            # Stop when it reaches min increment\n",
    "            else:\n",
    "                if(increment <= minIncrement):\n",
    "                    print(\"The min increment change of parameters hass been reached!\")\n",
    "                    break\n",
    "                    \n",
    "    # Predict the classification result with test dataset\n",
    "    def predict(self, X):\n",
    "        # calculating intercepts\n",
    "        intercepts = np.ones((X.shape[0], 1))\n",
    "        X = np.c_[X, intercepts]\n",
    "        # calculating probability\n",
    "        py = self.calProbability(X)\n",
    "        # deciding class by probability\n",
    "        return [0 if x <=0.5 else 1 for x in py]\n",
    "  \n",
    "    \n",
    "# File path\n",
    "filename = \"./breast-cancer-wisconsin.data\";\n",
    "# Create a dataset object, which will load this file\n",
    "data = dataset(filename)\n",
    "\n",
    "# Initial average accuracy value over 10 trials for mine implement and Scikit Learn\n",
    "avg_accuracy1 = 0\n",
    "avg_accuracy2 = 0\n",
    "\n",
    "# 10 trials\n",
    "for i in range(10):\n",
    "    # Get randomly X_train, X_test, y_train, y_test by split function\n",
    "    X_train, X_test, y_train, y_test = data.split()\n",
    "    \n",
    "    # The logistic Regression model from mine implement\n",
    "    model1 = mineLogisticRegression(X_train, y_train) \n",
    "    # Trainning model\n",
    "    model1.fit(X_train, y_train, 100, 10**(-4))\n",
    "    # Predict over test data\n",
    "    predict1 = model1.predict(X_test)\n",
    "    # Get accuracy for each trial\n",
    "    confMatrix1 = metrics.confusion_matrix(y_test, predict1)\n",
    "    accuracy1  = metrics.accuracy_score(y_test, predict1)\n",
    "    print(accuracy1)\n",
    "    # Calculate average accuracy\n",
    "    avg_accuracy1 += accuracy1/10\n",
    "    \n",
    "    # The logistic Regression model from Scikit Learn\n",
    "    model2 = LogisticRegression(solver = 'newton-cg')\n",
    "    # Trainning model\n",
    "    model2.fit(X_train, y_train)\n",
    "    # Predict over test data\n",
    "    predict2 = model2.predict(X_test)\n",
    "    # Get accuracy for each trial\n",
    "    confMatrix2 = metrics.confusion_matrix(y_test, predict2)\n",
    "    accuracy2  = metrics.accuracy_score(y_test, predict2)\n",
    "    print(accuracy2)\n",
    "    # Calculate average accuracy\n",
    "    avg_accuracy2 += accuracy2/10\n",
    "\n",
    "# Print result\n",
    "print(\"Mine implement: the average accuracy over 10 trials is \", avg_accuracy1)\n",
    "print(\"Scikit Learn: the average accuracy over 10 trials is \", avg_accuracy2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
